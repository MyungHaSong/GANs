{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from songe.tf_layer import tf_toolkit as tl\n",
    "from songe.tf_layer import activation as ac\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec as gridspec\n",
    "import random\n",
    "from skimage import io\n",
    "import tensorflow as tf \n",
    "from PIL import Image\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images):\n",
    "    if images.shape[3] == 3:\n",
    "        c = images.shape[3]\n",
    "        images = np.reshape(images, [images.shape[0], -1])\n",
    "        sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "        sqrtimg = int(np.ceil(np.sqrt(images.shape[1]/c)))\n",
    "        fig = plt.figure(figsize = (7,7))\n",
    "        gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "        gs.update(wspace = 0.05, hspace = 0.05)\n",
    "    \n",
    "        for i, img in enumerate(images):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(img.reshape([sqrtimg,sqrtimg,c]))\n",
    "    else:\n",
    "        images = np.reshape(images, [images.shape[0], -1])\n",
    "        sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "        sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "        fig = plt.figure(figsize = (7, 7))\n",
    "        gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "        gs.update(wspace = 0.05, hspace = 0.05)\n",
    "    \n",
    "        for i, img in enumerate(images):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(img.reshape([sqrtimg,sqrtimg]), cmap = plt.cm.gray)\n",
    "    return \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing():\n",
    "    bag_dir = \"./datasets/discogan/edges2handbags/train/\"\n",
    "    shoe_dir = \"./datasets/discogan/edges2shoes/train/\"\n",
    "\n",
    "    bag_list = glob.glob(bag_dir+'*.jpg')\n",
    "    shoe_list = glob.glob(shoe_dir+'*.jpg')\n",
    "    \n",
    "    bag_path = './datasets/discogan/edges2handbags/bags_train/'\n",
    "    shoe_path = \"./datasets/discogan/edges2shoes/shoes_train/\"\n",
    "\n",
    "    if not os.path.exists(bag_path):\n",
    "        os.mkdir(bag_path)\n",
    "    if not os.path.exists(shoe_path):\n",
    "        os.mkdir(shoe_path)\n",
    "    \n",
    "\n",
    "    for idx ,i in enumerate(bag_list):\n",
    "        image = Image.open(i)\n",
    "        image = image.resize([128,64])\n",
    "        image = image.crop([64,0,128,64])\n",
    "        image.save(bag_path+str(idx)+'.jpg')\n",
    "\n",
    "    for idx, i in enumerate(shoe_list):\n",
    "        image = Image.open(i)\n",
    "        image = image.resize([128,64])\n",
    "        image = image.crop([64,0,128,64])\n",
    "        image.save(shoe_path+str(idx)+'.jpg')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discogan:\n",
    "    def __init__(self, batch_size, training_epoch):\n",
    "        self.batch_size = batch_size\n",
    "        self.training_epoch = training_epoch\n",
    "        self.c_dim = 3\n",
    "        self.image_shape = [64,64,self.c_dim]\n",
    "        self.lambda_ = 10 \n",
    "        self.learning_rate = 0.0002\n",
    "        self.bag_path = './datasets/discogan/edges2handbags/bags_train/'\n",
    "        self.shoes_path = './datasets/discogan/edges2shoes/shoes_train/'\n",
    "\n",
    "        \n",
    "    def discriminator(self,x,name, reuse = False, is_train = True):\n",
    "        with tf.variable_scope(\"discriminator\"+name, reuse = reuse):\n",
    "            net = ac.lrelu(tl.conv(x,64,4,2,\"d_1\"))\n",
    "            net = ac.lrelu(tl.batch_norm(tl.conv(net,64*2,4,2,\"d_2\")))\n",
    "            net = ac.lrelu(tl.batch_norm(tl.conv(net,64*4,4,2,\"d_3\")))\n",
    "            net = ac.lrelu(tl.batch_norm(tl.conv(net,64*8,4,2,\"d_4\")))\n",
    "            net = tl.conv(net,1,4,2,\"d_5\",padding = \"VALID\")\n",
    "        return net\n",
    "    \n",
    "    def generator(self,x,name, reuse = False, is_train = True):\n",
    "        with tf.variable_scope(\"generator\"+name, reuse = reuse):\n",
    "            \"Encoder\"\n",
    "            net = ac.lrelu(tl.conv(x, 64, 4,2, \"g_1\"))\n",
    "            net = ac.lrelu(tl.batch_norm(tl.conv(net, 64*2,4,2,\"g_2\")))\n",
    "            net = ac.lrelu(tl.batch_norm(tl.conv(net, 64*4,4,2,\"g_3\")))\n",
    "            net = ac.lrelu(tl.batch_norm(tl.conv(net, 64*8,4,2,\"g_4\")))\n",
    "            net = ac.lrelu(tl.batch_norm(tl.conv(net, 100, 4,1,\"g_5\", padding = \"VALID\")))\n",
    "\n",
    "            \"Decoder\"\n",
    "            net = ac.relu(tl.batch_norm(tl.conv_tran(net, 64*8, 4,2,\"g_6\",padding = \"VALID\")))\n",
    "            net = ac.relu(tl.batch_norm(tl.conv_tran(net, 64*4, 4,2,\"g_7\")))\n",
    "            net = ac.relu(tl.batch_norm(tl.conv_tran(net, 64*2, 4,2,\"g_8\")))\n",
    "            net = ac.relu(tl.batch_norm(tl.conv_tran(net, 64, 4,2,\"g_9\")))\n",
    "            net = ac.tanh(tl.conv_tran(net, 3, 4,2,\"g_10\"))\n",
    "        return net\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.input_A = tf.placeholder(tf.float32, shape = [None]+self.image_shape)\n",
    "        self.input_B = tf.placeholder(tf.float32, shape = [None]+self.image_shape)\n",
    "        \n",
    "        A2B = self.generator(self.input_A,\"_inputAtoB\")\n",
    "        B2A = self.generator(self.input_B,\"_inputBtoA\")\n",
    "        self.sample_A2B = self.generator(self.input_A,\"_inputAtoB\",reuse= True)\n",
    "        self.sample_B2A = self.generator(self.input_B,\"_inputBtoA\",reuse = True)\n",
    "        A2B2A = self.generator(A2B,\"_inputBtoA\", reuse= True)\n",
    "        B2A2B = self.generator(B2A,\"_inputAtoB\", reuse = True)\n",
    "        \n",
    "        # discrimonator --> real image discrimination logit\n",
    "        discriminatorA = self.discriminator(self.input_A,\"_A_discriminator\")\n",
    "        discriminatorB = self.discriminator(self.input_B,\"_B_discriminator\")\n",
    "        \n",
    "        # discriminator --> A2B , B2A data discrimination logit\n",
    "        discriminatorB_A = self.discriminator(A2B,\"_A_discriminator\", reuse= True)\n",
    "        discriminatorA_B = self.discriminator(B2A,\"_B_discriminator\", reuse= True)\n",
    "        \n",
    "        # discriminator --> real_image d_loss\n",
    "        real_A_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= discriminatorA, labels= tf.ones_like(discriminatorA)))\n",
    "        real_B_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= discriminatorB, labels= tf.ones_like(discriminatorB)))\n",
    "        \n",
    "        # discriminator -->? fake_image d_loss\n",
    "        fake_A_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= discriminatorB_A, labels= tf.zeros_like(discriminatorB_A)))\n",
    "        fake_B_loss= tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= discriminatorA_B, labels= tf.zeros_like(discriminatorA_B)))\n",
    "        \n",
    "        # generator --> generator가 만들어내는 이미지를 진실로 판단할 수 있게 학습\n",
    "        g_A_B_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = discriminatorA_B, labels = tf.ones_like(discriminatorA_B)))\n",
    "        g_B_A_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = discriminatorB_A, labels = tf.ones_like(discriminatorB_A)))\n",
    "        \n",
    "        \n",
    "        # Total Discriminator Loss\n",
    "        loss_D_A = (real_A_loss + fake_A_loss) * 0.5\n",
    "        loss_D_B = (real_B_loss + fake_B_loss) * 0.5\n",
    "        self.loss_D = loss_D_A + loss_D_B\n",
    "        \n",
    "        # reconstruction Loss\n",
    "        A_reconstruction_loss = tf.reduce_sum(tf.losses.mean_squared_error\n",
    "(self.input_A,A2B2A))\n",
    "        B_reconstruction_loss = tf.reduce_sum(tf.losses.mean_squared_error\n",
    "(self.input_B,B2A2B))\n",
    "        # Total Generator Loss\n",
    "        self.loss_G = (g_A_B_loss + g_B_A_loss)*0.5 + self.lambda_ *(A_reconstruction_loss + B_reconstruction_loss)\n",
    "        \n",
    "        # training variables\n",
    "#         g_vars_AtoB = tf.get_collection(tf.GraphKeys.TRAINABLE_RESOURCE_VARIABLES, scope=\"generator_inputAtoB\")\n",
    "#         g_vars_BtoA = tf.get_collection(tf.GraphKeys.TRAINABLE_RESOURCE_VARIABLES, scope=\"generator_inputBtoA\")\n",
    "#         d_vars_AtoB = tf.get_collection(tf.GraphKeys.TRAINABLE_RESOURCE_VARIABLES, scope=\"discriminator_A_discriminator\")\n",
    "#         d_vars_BtoA = tf.get_collection(tf.GraphKeys.TRAINABLE_RESOURCE_VARIABLES, scope=\"discriminator_B_discriminator\")\n",
    "    \n",
    "#         self.g_vars = g_vars_AtoB + g_vars_BtoA\n",
    "#         self.d_vars = d_vars_AtoB + d_vars_BtoA\n",
    "        t_vars = tf.trainable_variables()\n",
    "        g_vars = [var for var in t_vars if 'g_' in var.name]\n",
    "        d_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "\n",
    "        # Define Optimizer\n",
    "        self.d_trainer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss_D,var_list = d_vars)\n",
    "        self.g_trainer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss_G,var_list = g_vars)\n",
    "        \n",
    "    def train(self):\n",
    "        self.build_model()\n",
    "        data_num = len(glob.glob( self.shoes_path + '*.jpg'))\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            total_batch = int(data_num/ self.batch_size)\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "            for epoch in range(self.training_epoch):\n",
    "                bag_file_list =  glob.glob(self.bag_path+'*.jpg')\n",
    "                shoe_file_list =  glob.glob(self.shoes_path+'*.jpg')\n",
    "                \n",
    "                for iteration in range(total_batch):\n",
    "                    random.shuffle(bag_file_list)\n",
    "                    random.shuffle(shoe_file_list)              \n",
    "\n",
    "                    bag_image,bag_file_list = batch(bag_file_list,self.batch_size)\n",
    "                    shoe_image,shoe_file_list = batch(shoe_file_list, self.batch_size)\n",
    "                    \n",
    "                    bag_image = bag_image / 255.0\n",
    "                    shoe_image = shoe_image / 255.0\n",
    "                    \n",
    "                    _, g_loss_val = sess.run([self.g_trainer, self.loss_G], feed_dict = {self.input_A : bag_image, self.input_B : shoe_image})\n",
    "                    _, d_loss_val = sess.run([self.d_trainer, self.loss_D], feed_dict = {self.input_A : bag_image, self.input_B : shoe_image})\n",
    "                    \n",
    "                    sampleAtoB = sess.run(self.sample_A2B, feed_dict = {self.input_A : bag_image, self.input_B : shoe_image})\n",
    "                    sampleBtoA = sess.run(self.sample_B2A, feed_dict = {self.input_A : bag_image, self.input_B : shoe_image})\n",
    "                    \n",
    "                    \n",
    "                    print(\"Epcch : {} , D_loss : {} , G_loss : {}\".format(epoch, d_loss_val, g_loss_val))\n",
    "                sample_image = np.concatenate([sampleAtoB[:16],sampleBtoA[:16]],axis = 0)\n",
    "                show_images(sample_image)\n",
    "                plt.savefig('./result/discogan/{}.png'.format(str(epoch).zfill(3)), bbox_inches = 'tight')\n",
    "                plt.show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(file_list,batch_size ):\n",
    "    file_list = list(file_list)        \n",
    "    random = file_list[:batch_size]\n",
    "    image_list = io.ImageCollection(random)\n",
    "    image = image_list.concatenate()\n",
    "\n",
    "    try :\n",
    "        for idx in range(batch_size):\n",
    "            file_list.pop(idx)\n",
    "    except IndexError:\n",
    "        print(\"next epoch\")\n",
    "     \n",
    "\n",
    "    return image, file_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "a = discogan(256,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
